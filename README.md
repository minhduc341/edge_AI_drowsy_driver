# edge_AI_drowsy_driver
Driver Drowsiness Detection using MobileNetV2 on STM32

ğŸ“Œ Project Overview
This project implements a lightweight object detection model to detect whether a driver is drowsy or not. It leverages a reduced MobileNetV2 backbone trained and converted for real-time inference on STM32H750 using STM32Cube.AI. The model takes grayscale input from a camera and displays predictions on an LCD screen.

ğŸ¯ Objectives
Detect drowsy vs. non-drowsy states in real-time

Use OV2640 to capture grayscale input (128x128 resolution)

Deploy deep learning model directly on STM32H750 (no cloud/edge server)

Display results on 0.96â€ TFT LCD screen

Run with minimal power and memory usage

ğŸ§  AI Model Details
Backbone: MobileNetV2 (width multiplier Î± = 0.1)

Truncated: first 5 blocks used (stride = 8)

Input: 128Ã—128 grayscale image â†’ repeated to 3 channels

Output: feature map size (3 Ã— 16 Ã— 16)

0 = background

1 = drowsy

2 = non-drowsy

Head:

Depthwise Conv + Pointwise Conv

Interpolated to 16x16 output grid

Activation: ReLU

Trained using PyTorch and exported via X-Cube.AI

ğŸ›  Hardware & Software Requirements
ğŸ§© Hardware:

STM32H750 board (tested on STM32H750VBT6)

OV2640 camera (connected via DCMI)

0.96â€ TFT LCD (SPI interface)

Optional: External QSPI Flash (for model storage)

ğŸ’» Software:

STM32CubeIDE

Python 3.10+

PyTorch

OpenCV (for preprocessing and augmentation)

Jupyter Notebook (optional for training scripts)

ğŸ“¦ Project Structure
.
â”œâ”€â”€ model/ # AI model files
â”‚ â”œâ”€â”€ mobilenetv2_fomo.pt
â”‚ â”œâ”€â”€ model.onnx
â”‚ â””â”€â”€ ai_model.c/.h (from X-Cube-AI)
â”œâ”€â”€ data/ # Training and validation data
â”‚ â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ test/
â”‚ â””â”€â”€ _annotations.csv
â”œâ”€â”€ stm32_project/ # STM32CubeIDE project
â”‚ â”œâ”€â”€ Core/
â”‚ â”œâ”€â”€ Inc/
â”‚ â”œâ”€â”€ Src/
â”‚ â””â”€â”€ main.c
â”œâ”€â”€ notebooks/ # Training & conversion notebooks
â”‚ â”œâ”€â”€ train_model.ipynb
â”‚ â””â”€â”€ convert_model_xcubeai.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸš€ Getting Started
Clone the repository

Train the model (optional, model is provided)

Convert model to C array using X-Cube-AI

Open stm32_project in STM32CubeIDE

Flash firmware to STM32H750

Connect camera + LCD and run

ğŸ“ˆ Performance
Accuracy on test set: ~75%

Model complexity: 24.98M MACC

Flash usage: ~30 KB (model only)

RAM usage: ~407 KB

Real-time FPS on STM32H750: ~15 FPS

ğŸ”§ Re-training & Conversion
Training data format: 128Ã—128 grayscale images

Labels: stored in _annotations.csv (bounding boxes + class)

Conversion path:
â†’ PyTorch (.pth) â†’ ONNX â†’ X-Cube-AI (.c/.h)

ğŸ“‹ Inference Logic
Image divided into 16Ã—16 grid

For each grid cell:

If overlaps with a bounding box:
â†’ label = 1 (drowsy) or 2 (non-drowsy)

Else: label = 0

Output: 3x16x16 probability map

ğŸ“ License
This project is licensed under the MIT License.
Please refer to LICENSE file for details.

Note: The dataset used is derived from synthetic driving scenes in Roblox and is intended for educational/research use only.

ğŸ“· Demo Image

