# Drowsiness Detection using MobileNetV2 on STM32H750

---

## ğŸ“Œ Project Overview

This project implements a lightweight object detection model to detect whether a driver is drowsy or not. It leverages a reduced MobileNetV2 backbone trained and converted for real-time inference on STM32H750 using STM32Cube.AI. The model takes grayscale input from a camera and displays predictions on an LCD screen.

Target application: embedded, on-device drowsiness monitoring for smart vehicles or helmets.

---

## ğŸ¯ Objectives

- Detect drowsy vs. non-drowsy states in real-time
- Use grayscale camera input (128x128 resolution)
- Deploy deep learning model directly on STM32H750 (no cloud/edge server)
- Display results on 0.96â€ TFT LCD screen
- Run with minimal power and memory usage

---

## ğŸ§  AI Model Details

- Backbone: MobileNetV2 (width multiplier Î± = 0.1)
- Truncated: first 5 blocks used (stride = 8)
- Input: 128Ã—128 grayscale image â†’ repeated to 3 channels
- Output: feature map size (3 Ã— 16 Ã— 16)
  - 0 = background
  - 1 = drowsy
  - 2 = non-drowsy
- Head:
  - Depthwise Conv + Pointwise Conv
  - Interpolated to 16x16 output grid
- Activation: ReLU
- Trained using PyTorch and exported via X-Cube.AI

---

## ğŸ›  Hardware & Software Requirements

ğŸ§© Hardware:

- WeAct STM32H750 board [link](https://github.com/WeActStudio/MiniSTM32H7xx)
- OV2640 camera 
- 0.96â€ TFT LCD 

ğŸ’» Software:

- STM32CubeIDE
- Python 3.10+
- PyTorch
- OpenCV
- Jupyter Notebook

---

## ğŸ“¦ Project Structure

```
.
â”œâ”€â”€ model/
â”‚ â”œâ”€â”€ best_model_grayscale_128x128_24_05_2025.pth
â”‚ â””â”€â”€ best_model_grayscale_128x128_24_05_2025.onnx
â”œâ”€â”€ dataset/
â”‚ â”œâ”€â”€ train/
â”‚ â”‚ â””â”€â”€_annotations.csv
â”‚ â”œâ”€â”€ valid
â”‚ â”‚ â””â”€â”€_annotations.csv
â”‚ â””â”€â”€ test/
â”‚   â””â”€â”€_annotations.csv
â”œâ”€â”€ stm32_project/ # STM32CubeIDE project
â”‚ â”œâ”€â”€ Core/
â”‚ â”œâ”€â”€ Drivers/
â”‚ â””â”€â”€ edge_AI_drowsiness.ioc
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ train_model.ipynb
â””â”€â”€ README.md
```

---


## ğŸš€ Getting Started

1. Clone the repository
2. Train the model (optional, model is provided)
3. Convert model to C array using X-Cube-AI
4. Open stm32_project in STM32CubeIDE
5. Flash firmware to STM32H750
6. Connect camera + LCD and run

---


## ğŸ“ˆ Performance

- Accuracy on test set: ~80%
- Model complexity: 24.98M MACC
- Flash usage: ~30 KB (model only)
- RAM usage: ~407 KB
- Real-time FPS on STM32H750: ~15 FPS

---


## ğŸ“ License

This project is licensed under the MIT License.  
Please refer to LICENSE file for details.

Note: The dataset used is derived from synthetic driving scenes in Roblox and is intended for educational/research use only.

---


ğŸ“· [Demo Video](https://youtu.be/xnOyMFRJEb4)
